{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t\t\t\t\t\t\t\n",
    "Descriptive statistics on the number of positive labels for across   all customers\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\n",
    "\tMinimum\tMaximum\tMean\tStandard deviation\tMedian\t\t\n",
    "\t1\t2\t1\t1.5\t1\t\t\n",
    "\t\t\t\t\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import start_spark_session, get_imputed_df\n",
    "from col_stats import *\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = start_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df = get_imputed_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "take the targets where target is equal 1, group by party id, count how many 1 targets\n",
    "\"\"\"\n",
    "imputed_df_count = imputed_df.where(\"te_2month = 1\").groupBy('party_id').agg({'te_2month' : 'count'})\n",
    "imputed_df_count_te_2month = imputed_df_count.select(\"count(te_2month)\")\n",
    "minimum = calc_column_min(imputed_df_count_te_2month)\n",
    "maximum = calc_column_max(imputed_df_count_te_2month)\n",
    "mean = calc_column_avg(imputed_df_count_te_2month)\n",
    "stdev = calc_column_stddev(imputed_df_count_te_2month)\n",
    "median = calc_column_median(imputed_df_count_te_2month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+-----+------+\n",
      "|minimum|maximum| mean|stdev|median|\n",
      "+-------+-------+-----+-----+------+\n",
      "|      1|     89|32.48|13.76|  25.0|\n",
      "+-------+-------+-----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame([[minimum, maximum, mean, stdev, median]],\\\n",
    "                      ['minimum', 'maximum','mean','stdev','median']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
