{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "te_config_modulePSEUDO CODE:\n",
    "1. Get TE_WINDOW from /home/boldyrek/mysoft/te/te_code_v_2_7/terminal/ATLAS_1.2/config\n",
    "get_module_from_path( module_name , module_path ): 15 min / took 30 mins\n",
    "1.5 load pickle file 15 min /start 2:20 / 12 min\n",
    "2. if colum is aggeragted or not to be speicifed in config file:\n",
    "    cfg.AGGREGATIONS\n",
    "    col_and_its_aggreagation =[]\n",
    "    for list_of_aggregations in cfg.AGGREGATIONS:            \n",
    "        for col in cols: \n",
    "            if col in list:\n",
    "                col_and_its_aggregation.append( col, list_of_aggregations )\n",
    "            else: \n",
    "                col_and_its_aggregation.append( col, 'there is no aggregation' )\n",
    "            \n",
    "    AGGREGATIONS = ['CUMSUM_COLS','CUMMAX_COLS']\n",
    "    Feature aggregation logic \n",
    "start 2:35 / 30 mins / 50 min\n",
    "3. Feature enrichment logic: load_pipeline_config.py\n",
    "\n",
    "60 mins ? / 16:30 : 17:40/ 9:40  - 12:40 \n",
    "4. Feature descriptive statistics \n",
    "    def get_df_with_descriptive_stats_for_columns( spark , df):\n",
    "20 mins/14:32 = 14:47/ \n",
    "5. Join 4,2,3 20 mins\n",
    "6. create script file 20 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/boldyrek/mysoft/te/te_reporting/\")\n",
    "import config_te_reporting as cfg\n",
    "import os \n",
    "import importlib.util\n",
    "from helper_functions import get_te_config_module, load_final_train_df,  get_te_constants_module\n",
    "from helper_functions import start_spark_session, get_imputed_df ,get_te_load_pipeline_config_module\n",
    "from col_stats import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_every_aggregation_from_cfg( col ):\n",
    "    \"\"\"\n",
    "    function aggregate_over_days does aggregations of multiple ctus to \n",
    "    on ctu in  base_enrich_data_pd.py\n",
    "    it check cfg['rolling_agg_cols'], cfg['CUMMAX_COLS'], cfg['CUMMEDIAN_COLS']\n",
    "    cfg['ID_COL'] it is a lag features that adds _lag_ to column name\n",
    "    DiFF [x+'_diff' for x in df_diff.columns]\n",
    "     Creates rate columns cols = [x+'_rate' for x in rate_cols]\n",
    "     create cyclical feature 'df[feat+'_sin', df[feat+'_cos']\n",
    "     lag features\n",
    "\n",
    "    \"\"\"\n",
    "    te_constants_module = get_te_constants_module()\n",
    "    col_aggregations = ''\n",
    "    for aggregation in cfg.AGGREGATIONS:\n",
    "        if col  in getattr(te_constants_module, aggregation):\n",
    "            col_aggregations += aggregation + ',' \n",
    "    \n",
    "    return col_aggregations\n",
    "\n",
    "def get_cols_aggregations_df( columns):\n",
    "    \n",
    "    col_and_its_aggregation = []\n",
    "    for col in columns:\n",
    "        col_aggregations = check_every_aggregation_from_cfg( col )\n",
    "        col_and_its_aggregation.append((col,col_aggregations))       \n",
    "    col_and_its_aggregation = spark.createDataFrame(col_and_its_aggregation, [\"column_name_agg\", \"aggregation\"])\n",
    "    return col_and_its_aggregation\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = start_spark_session()\n",
    "# STEP 2\n",
    "te_constants_module =  get_te_constants_module()\n",
    "final_train_df = get_imputed_df(cfg.IMPUTATION_TRAIN_PATH, cfg.IMPUTATION_PREDICT_PATH)\n",
    "columns_final_train = final_train_df.columns\n",
    "col_and_its_aggregation = get_cols_aggregations_df( columns_final_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enriched_train_2020_08_17_1.csv\r\n",
      "enriched_train_2020_08_17_1.feather\r\n",
      "enriched_train_2020_08_17_no_outliers_1.feather\r\n",
      "final_predict_2020_08_17.pkl\r\n",
      "final_train_2020_08_17_1.pkl\r\n",
      "final_train_2020_08_17_2.pkl\r\n",
      "final_train_2020_08_17_3.pkl\r\n",
      "final_train_2020_08_17_full.pkl\r\n",
      "final_train_test_out_of_sample_2020_08_17.pkl\r\n",
      "general_preprocessing_2020_08_17_1.csv\r\n",
      "general_preprocessing_2020_08_17_1.feather\r\n",
      "imputed_predict_2020_08_17_1.csv\r\n",
      "imputed_train_2020_08_17_1.csv\r\n",
      "imputed_train_2020_08_17_1.feather\r\n",
      "model_LGBM_2020_08_17.pkl\r\n",
      "pred_scores_LGBM_2020_08_17.pkl\r\n",
      "pred_scores_LGBM_train_2020_08_17.pkl\r\n",
      "preprocessing_2020_08_17_1.csv\r\n",
      "preprocessing_2020_08_17_1.feather\r\n",
      "sampled_2020_08_17_1.pkl\r\n",
      "sampled_2020_08_17_2.pkl\r\n",
      "sampled_2020_08_17_3.pkl\r\n",
      "sampled_2020_08_17_full.pkl\r\n",
      "split_pred_2020_08_17_1.pkl\r\n",
      "split_train_2020_08_17_1.pkl\r\n",
      "split_validate_2020_08_17_1.pkl\r\n",
      "Te_logfile_2020_08_17.log\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/boldyrek/mysoft/te/data_plus_enrichment_funcs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4\n",
    "imputed_df = get_imputed_df(cfg.IMPUTATION_TRAIN_PATH, cfg.IMPUTATION_PREDICT_PATH)\n",
    "final_train_descriptive_stats = get_df_with_descriptive_stats_for_columns ( spark ,\n",
    "                                                                           imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['column_name_agg', 'aggregation']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 5\n",
    "final_train_descriptive_stats.columns\n",
    "col_and_its_aggregation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['party_id',\n",
       " 'CTU',\n",
       " 'level_0',\n",
       " 'index',\n",
       " 'Unnamed: 0',\n",
       " 'event_date',\n",
       " 'cai_ins_grs_vmc',\n",
       " 'cai_ins_grs_mrc',\n",
       " 'cai_ins_grs_erc',\n",
       " 'cai_ins_grs_evmc',\n",
       " 'cai_ins_grs_vuc',\n",
       " 'cai_ins_grs_evnt_1',\n",
       " 'cai_ins_grs_evnt_2',\n",
       " 'cai_ins_grs_evnt_3',\n",
       " 'cai_ins_grs_rand',\n",
       " 'cai_factor_age',\n",
       " 'cai_factor_1',\n",
       " 'cai_factor_2',\n",
       " 'event_id',\n",
       " 'expanding_cai_ins_grs_vmc',\n",
       " 'expanding_cai_ins_grs_mrc',\n",
       " 'expanding_cai_ins_grs_erc',\n",
       " 'expanding_cai_ins_grs_evmc',\n",
       " 'expanding_cai_ins_grs_vuc',\n",
       " 'expanding_cai_ins_grs_evnt_1',\n",
       " 'expanding_cai_ins_grs_evnt_2',\n",
       " 'expanding_cai_ins_grs_evnt_3',\n",
       " 'REF_EVENT',\n",
       " 'td_start',\n",
       " 'year',\n",
       " 'month',\n",
       " 'yr_month',\n",
       " 'event_inbound_interactions',\n",
       " 'event_outbound_interactions',\n",
       " 'event_positive_interactions',\n",
       " 'event_negative_interactions',\n",
       " 'td_last_cai_ins_grs_vmc',\n",
       " 'td_last_cai_ins_grs_mrc',\n",
       " 'td_last_cai_ins_grs_erc',\n",
       " 'td_last_cai_ins_grs_evmc',\n",
       " 'td_last_cai_ins_grs_vuc',\n",
       " 'td_last_cai_ins_grs_evnt_1',\n",
       " 'td_last_cai_ins_grs_evnt_2',\n",
       " 'td_last_cai_ins_grs_evnt_3',\n",
       " 'imputed_ctu',\n",
       " 'te_2month',\n",
       " 'normal_2']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8e7b9895361f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'columns' is not defined"
     ]
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3\n",
    "\"\"\"\n",
    "All the affixes for this step are derived from base_enrich_data_pd.py and \n",
    "can be manually added to config.py\n",
    "We use columns names to see if they have enrichment affixes\n",
    "Pseudocode:\n",
    "1. Take one column\n",
    "2. pass col to get enrichment type\n",
    "    a. in enrichment type loop through all the affixes and if the affix is inside a colum\n",
    "    cut the affix taking last part of it _mean, an remove underscore\n",
    "    if there is a _lag_5 then remove lag_5 for example\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "def get_enrichment_type( col ):\n",
    "    import re\n",
    "    for affix in cfg.ENRICHMENT_AFFIXES:\n",
    "        if affix not in col:\n",
    "            #print(f\"{affix} not in {col}\" )\n",
    "            continue\n",
    "        elif '_lag_' in col:\n",
    "                return 'lag'\n",
    "        else:\n",
    "           transformation = affix.split('_')\n",
    "           return transformation[-1]\n",
    "        return None\n",
    "    \n",
    "col_and_enrichment = []    \n",
    "for col in columns:\n",
    "    enrichment_type = get_enrichment_type( col ) \n",
    "    if enrichment_type != None:\n",
    "        print(col)\n",
    "        print(enrichment_type)\n",
    "        col_and_enrichment.append((col,enrichment_type))\n",
    "    col_and_enrichment.append((col,'None'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_and_enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "'cai_ins_grs_cntrb_m_vol_unmtch_amt_rolling_std',\n",
    "'cai_ins_grs_cntrb_m_vol_unmtch_amt_rolling_trend',\n",
    "'cai_ins_grs_cntrb_m_vol_unmtch_amt_diff',\n",
    "'year_sin',\n",
    "'mont_cos',\n",
    "'event_rate',\n",
    "'evet1_lag_1',\n",
    "'evetn2_diff',\n",
    "'price_per_unit',\n",
    "'payment_fail_ratio',\n",
    "'event3_rolling_trend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for affix in cfg.ENRICHMENT_AFFIXES:\n",
    "    print(f\"{affix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'my_rolling_trend'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step1 see if affix inside the column\n",
    "remove leading underscore\n",
    "\"\"\"\n",
    "import re\n",
    "match = re.search(affix, col)\n",
    "if match != None: print(match[0])\n",
    "    re.findall(r'_\\w*_(\\w*)' , affix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.ENRICHMENT_AFFIXES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting last part of an affix\n",
    "re.search(r'_\\b.*\\b' , affix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affix =\"_diff\"\n",
    "affix = '_rolling_trend'\n",
    "re.findall(r'^[_]+' , affix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affix.split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = start_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
