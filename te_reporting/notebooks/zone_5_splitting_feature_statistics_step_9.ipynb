{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nDifference in descriptive statistics between train and test\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\n\\tDelta minimum\\tDelta maximum\\tDelta mean\\tDelta standard deviation\\tDelta median\\tKl divergence\\tKS test\\nColumn 1\\t\\t\\t\\t\\t\\t\\t\\nColumn 2\\t\\t\\t\\t\\t\\t\\t\\nColumn 3\\t\\t\\t\\t\\t\\t\\t\\nColumn 4\\t\\t\\t\\t\\t\\t\\t\\nColumn 5\\t\\t\\t\\t\\t\\t\\t\\nColumn 6\\t\\t\\t\\t\\t\\t\\t\\nColumn 7\\t\\t\\t\\t\\t\\t\\t\\n\\nLoad \\n1. load imputed_train\\n   load imputed_test\\n2. calc min, max, sttdev, mean for train : get_descriptive_statistics_for_columns\\n calc min, max, sttdev, mean for test : get_descriptive_statistics_for_columns\\n3.join dfs :\\njoin select(*(col(x).alias(x + '_pre') for x in preprocessing_cols_stats_df.columns))\\njoined_df = preprocessing_cols_stats_df_re.join(imputed_cols_stats_df, preprocessing_cols_stats_df_re.column_pre == imputed_cols_stats_df.column)\\n\\n4. diffrence delts between columns : get_delta_columns_df(joined_df):\\n5. Caclulate KS divergence and kl divergence\\n6. K test\\n7. join delta_df, k_test, kl_divergence\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Difference in descriptive statistics between train and test\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\n",
    "\tDelta minimum\tDelta maximum\tDelta mean\tDelta standard deviation\tDelta median\tKl divergence\tKS test\n",
    "Column 1\t\t\t\t\t\t\t\n",
    "Column 2\t\t\t\t\t\t\t\n",
    "Column 3\t\t\t\t\t\t\t\n",
    "Column 4\t\t\t\t\t\t\t\n",
    "Column 5\t\t\t\t\t\t\t\n",
    "Column 6\t\t\t\t\t\t\t\n",
    "Column 7\t\t\t\t\t\t\t\n",
    "\n",
    "Load \n",
    "1. load imputed_train\n",
    "   load imputed_test\n",
    "2. calc min, max, sttdev, mean for train : get_descriptive_statistics_for_columns\n",
    " calc min, max, sttdev, mean for test : get_descriptive_statistics_for_columns\n",
    "3.join dfs :\n",
    "join select(*(col(x).alias(x + '_pre') for x in preprocessing_cols_stats_df.columns))\n",
    "joined_df = preprocessing_cols_stats_df_re.join(imputed_cols_stats_df, preprocessing_cols_stats_df_re.column_pre == imputed_cols_stats_df.column)\n",
    "\n",
    "4. diffrence delts between columns : get_delta_columns_df(joined_df):\n",
    "5. Caclulate KS divergence and kl divergence\n",
    "6. K test\n",
    "7. join delta_df, k_test, kl_divergence\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/boldyrek/mysoft/te/te_reporting/\")\n",
    "from helper_functions import get_imputed_df, start_spark_session, load_df\n",
    "from col_stats import *\n",
    "import config as cfg\n",
    "from helper_functions import *\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = start_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = spark.createDataFrame([(1,1,0),(1,1,1),(1,1,1),\n",
    "                                        (2,1,1),(2,2,0),\n",
    "                                            (3,1,1),(3,2,0),\n",
    "                                         (3,3,1),(3,3,0),\n",
    "                                        (4,3,0),(4,3,0)\n",
    "                                                  ], ['party_id', 'ctu', 'te_2month'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1\n",
    "\n",
    "#imputed_train = load_df( cfg.IMPUTATION_TRAIN_PATH )\n",
    "#imputed_predict = load_df( cfg.IMPUTATION_PREDICT_PATH )\n",
    "imputed_train = test_df\n",
    "imputed_predict = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "party_id\n",
      "ctu\n",
      "te_2month\n",
      "[('party_id', 4, 1, 2.45, 1.13, 2.0), ('ctu', 3, 1, 1.91, 0.94, 1.0), ('te_2month', 1, 0, 0.45, 0.52, 0.0)]\n",
      "party_id\n",
      "ctu\n",
      "te_2month\n",
      "[('party_id', 4, 1, 2.45, 1.13, 2.0), ('ctu', 3, 1, 1.91, 0.94, 1.0), ('te_2month', 1, 0, 0.45, 0.52, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# step 2\n",
    "#imputed_train = drop_garbage_cols( imputed_train )\n",
    "imputed_train_descriptive_stats = get_df_with_descriptive_stats_for_columns ( spark,  imputed_train )\n",
    "imputed_predict_descriptive_stats = get_df_with_descriptive_stats_for_columns ( spark, imputed_predict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+---+----+------+------+\n",
      "|column_name|min|max|mean|stddev|median|\n",
      "+-----------+---+---+----+------+------+\n",
      "|   party_id|  4|  1|2.45|  1.13|   2.0|\n",
      "|        ctu|  3|  1|1.91|  0.94|   1.0|\n",
      "|  te_2month|  1|  0|0.45|  0.52|   0.0|\n",
      "+-----------+---+---+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputed_train_descriptive_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+---+----+------+------+\n",
      "|column_name|min|max|mean|stddev|median|\n",
      "+-----------+---+---+----+------+------+\n",
      "|   party_id|  4|  1|2.45|  1.13|   2.0|\n",
      "|        ctu|  3|  1|1.91|  0.94|   1.0|\n",
      "|  te_2month|  1|  0|0.45|  0.52|   0.0|\n",
      "+-----------+---+---+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputed_predict_descriptive_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 join dfs\n",
    "joined_descriptive_stats= suffix_and_join_dfs( \n",
    "    imputed_train_descriptive_stats, imputed_predict_descriptive_stats, 'column_name' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 delta\n",
    "delta_df = get_delta_descriptive_stats_df(joined_descriptive_stats, '2' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+----------+------------+------------+\n",
      "|column_name|delta_min|delta_max|delta_mean|delta_stddev|delta_median|\n",
      "+-----------+---------+---------+----------+------------+------------+\n",
      "|        ctu|        0|        0|       0.0|         0.0|         0.0|\n",
      "|   party_id|        0|        0|       0.0|         0.0|         0.0|\n",
      "|  te_2month|        0|        0|       0.0|         0.0|         0.0|\n",
      "+-----------+---------+---------+----------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+---+\n",
      "|column_name_ks|p_value| kd|\n",
      "+--------------+-------+---+\n",
      "|      party_id|    0.0|1.0|\n",
      "|           ctu|    0.0|1.0|\n",
      "|     te_2month|    0.0|1.0|\n",
      "+--------------+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5 ks stats\n",
    "def get_df_with_ks_stats( imputed_train, imputed_predict ):\n",
    "    columns = imputed_train.schema.names\n",
    "    col_ks = []\n",
    "    for col in columns:\n",
    "        imputed_train_col = imputed_train.select(col).toPandas()[col].tolist()\n",
    "        imputed_predict_col = imputed_predict.select(col).toPandas()[col].tolist()\n",
    "        try:\n",
    "            ks = stats.ks_2samp(imputed_train_col, imputed_predict_col)\n",
    "            p_value = str(round(ks[0], 2))\n",
    "            \n",
    "            kd = str(round(ks[1], 2))\n",
    "\n",
    "        except Exception as e:\n",
    "            print('col ',col ,e)\n",
    "            p_value = ''\n",
    "            kd = ''      \n",
    "        col_ks.append((col,p_value, kd))   \n",
    "    ks_stats_df = spark.createDataFrame(col_ks, ['column_name_ks', 'p_value', 'kd'])\n",
    "    return ks_stats_df\n",
    "ks_stats_df = get_df_with_ks_stats (imputed_train, imputed_predict )\n",
    "ks_stats_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6 KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+----------+------------+------------+--------------+-------+---+\n",
      "|column_name|delta_min|delta_max|delta_mean|delta_stddev|delta_median|column_name_ks|p_value| kd|\n",
      "+-----------+---------+---------+----------+------------+------------+--------------+-------+---+\n",
      "|        ctu|        0|        0|       0.0|         0.0|         0.0|           ctu|    0.0|1.0|\n",
      "|   party_id|        0|        0|       0.0|         0.0|         0.0|      party_id|    0.0|1.0|\n",
      "|  te_2month|        0|        0|       0.0|         0.0|         0.0|     te_2month|    0.0|1.0|\n",
      "+-----------+---------+---------+----------+------------+------------+--------------+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7 Join \n",
    "delta_df.join(ks_stats_df, col('column_name') == col('column_name_ks')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
